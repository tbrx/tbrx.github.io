<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="description" content="">
        <meta name="author" content="">

        <!-- Note there is no responsive meta tag here -->

        <title>brooks paige &#58;&#58; UCL machine learning</title>

        <!-- Bootstrap core CSS -->
        <link href="/bootstrap-3.1.1-dist/css/bootstrap.min.css" rel="stylesheet">

        <!-- Custom styles for this template -->
        <link href="/css/non-responsive.css" rel="stylesheet">

        <style>
        .light { font-weight: 200; }
        h4 { font-size: 21px; margin-top: 1.1em; }
        .jumbotron { background-color: #DEF; }
        </style>

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
          <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->
        
        <!-- syntax highlighting CSS -->
        <link rel="stylesheet" href="/css/syntax.css">

    </head>

    <body>

    <div class="container">

  <div class="row">
    <div class="col-xs-offset-2 col-xs-8">

      <h1 id="potential-msc-project-topics">Potential MSc project topics</h1>

      <p><a href="../">Back to main page</a></p>

      <p>If you are a current MSc student at UCL, please email me at <a href="mailto:b.paige@ucl.ac.uk">b.paige@ucl.ac.uk</a> if you are interested in working on the following projects, or would like to discuss some alternative (ideally, something related to one of my <a href="https://scholar.google.com/citations?user=JrFJmx0AAAAJ">publications</a>).</p>

      <h2 id="blind-and-not-so-blind-source-separation">Blind and (not-so-blind) source separation</h2>

      <p>The blind source separation problem (or “cocktail party problem”) involves decomposing a combined signal — for example, of multiple people talking simultaneously — into its independent generating components — for example, the individual separate voices. Two projects could be based on methods for blind source separation, looking at datasets of recorded music.</p>

      <p>The first project would be directly based on looking into methods for “transcribing” audio, and splitting recorded music out into different parts (be it different instruments / performers, or different notes). The talk [1] on youtube does a great job of introducing classic methods and describing recent advances. There is a dataset [2] of piano recordings aligned with transcriptions that could be a good starting point, and the same group has released other such datasets as well. This would provide an opportunity to explore a recently proposed family of deep generative models, related to independent components analysis [3].</p>

      <p>The second option would be based around “multimodal” models, looking at the dataset [4] of different people playing chamber music, including both video and audio. It could be interesting to look at this using some kind of joint modeling — e.g. using multi-modal generative models [5]. The most obvious “tasks” would be seeing (a) how adding the video could improve automatic transcription quality (intuitively, it should help do things like disambiguate who is playing what when…), or (b) how adding video can help with the source separation problem. (There are also some “funny” possibilities, e.g. given a video of people playing, but with the audio muted, try to guess how it sounds….)</p>

      <p>[1] Talk by Paris Smaragdis on non-negative matrix factorization: <a href="https://www.youtube.com/watch?v=wfmpViJIjWw">https://www.youtube.com/watch?v=wfmpViJIjWw</a></p>

      <p>[2] MAESTRO dataset: <a href="https://magenta.tensorflow.org/datasets/maestro">https://magenta.tensorflow.org/datasets/maestro</a></p>

      <p>[3] Variational Autoencoders and Nonlinear ICA: A Unifying Framework, <a href="http://proceedings.mlr.press/v108/khemakhem20a">http://proceedings.mlr.press/v108/khemakhem20a</a></p>

      <p>[4] Multi-Modal Music Performance (URMP) Dataset: <a href="http://www2.ece.rochester.edu/projects/air/projects/URMP.html">http://www2.ece.rochester.edu/projects/air/projects/URMP.html</a></p>

      <p>[5] Variational Mixture-of-Experts Autoencoders for Multi-Modal Deep Generative Models: <a href="https://arxiv.org/abs/1911.03393">https://arxiv.org/abs/1911.03393</a></p>

      <h2 id="generating-high-resolution-images-with-coordinate-based-neural-networks">Generating high-resolution images with coordinate-based neural networks</h2>

      <p>Most deep generative models for images model individual pixels. In contrast, coordinate-based networks learn a function f(i,j) -&gt; x_{i,j}, which maps directly from <em>pixel indices</em> i, j to the color value of the image at that location. These approaches are particular interesting because they can be evaluated at fractional coordinates for arbitrarily high resolutions! For two interesting artistic examples of this, see [1] and [2].</p>

      <p>Recent work [3] introduces a positional encoding scheme using Fourier features which seems to be able to capture high-frequency information accurately, leading to high-resolution photorealistic reconstructions of images.</p>

      <p>However, these models are still fit to only a single image! Naively, each image is encoded by a separate function, i.e. by a separate network. The goal of this project is to explore ways of developing these coordinate-based networks into generative models that can produce a range of images, without sacrificing image quality. There are a few options here: one is to consider a latent variable model, e.g. [4], as a way of introducing an additional “context” vector beyond the i, j coordinates into the network; another is to consider explicitly learning distributions over network weights, or even other deep networks which output network weights of the coordinate-based network (as in [5]).</p>

      <p>[1] <a href="https://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/">https://blog.otoro.net/2016/03/25/generating-abstract-patterns-with-tensorflow/</a></p>

      <p>[2] <a href="https://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/">https://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/</a></p>

      <p>[3] Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains, <a href="https://proceedings.neurips.cc/paper/2020/hash/55053683268957697aa39fba6f231c68-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/55053683268957697aa39fba6f231c68-Abstract.html</a></p>

      <p>[4] Auto-encoding variational Bayes, <a href="https://arxiv.org/abs/1312.6114v10">https://arxiv.org/abs/1312.6114v10</a></p>

      <p>[5] Hypernetworks, <a href="https://arxiv.org/abs/1609.09106">https://arxiv.org/abs/1609.09106</a></p>

      <h2 id="stochastic-normalizing-flows">Stochastic normalizing flows</h2>

      <p>Normalizing flows (see review paper [1]) provide a flexible means for defining complex density functions. They take a simple base distribution p(z) and transform it to a more expressive density p(x), by way of a bijective (invertible) deterministic function x = f(z) and making use of the change-of-variables formula.
However, the restriction to <em>deterministic</em> functions reduces the expressivity. One proposal is to replace it with a stochastic function.</p>

      <p>Two recent quite different papers both consider extensions with stochastic transformations. One considers instead surjective functions, focusing on generative modeling from data, and makes analogies to variational autoencoders [2]. The other aims to learning samplers for unnormalized probability distributions, and works by explicitly introducing Metropolis-Hastings steps into the flow [3]. A goal of this project is to better understand these normalizing flow variants, exploring their modeling capabilities with different choices of deterministic and stochastic functions.</p>

      <p>We can then explore other potentially novel approaches to constructing stochastic flows. One potential option could be to consider a Bayesian treatment of parameters in a deterministic normalizing flow.</p>

      <p>[1] Normalizing Flows for Probabilistic Modeling and Inference, <a href="https://arxiv.org/abs/1912.02762">https://arxiv.org/abs/1912.02762</a></p>

      <p>[2] SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows, <a href="https://proceedings.neurips.cc/paper/2020/hash/9578a63fbe545bd82cc5bbe749636af1-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/9578a63fbe545bd82cc5bbe749636af1-Abstract.html</a></p>

      <p>[3] Stochastic Normalizing Flows, <a href="https://proceedings.neurips.cc/paper/2020/hash/9578a63fbe545bd82cc5bbe749636af1-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/9578a63fbe545bd82cc5bbe749636af1-Abstract.html</a></p>

      <h2 id="deep-neural-networks-for-the-schrodinger-equation">Deep Neural Networks for the Schrodinger Equation</h2>

      <p><em>[Co-supervised with Andrea Karlova]</em></p>

      <p>The Schrodinger Equation provides an elegant description of the positions of the electrons in the molecular structures. Despite the fact that the equation has been known for nearly a century, providing the solution, which accurately characterises the wave functions, has remained a challenging task.</p>

      <p>Various numerical approaches have been developed, such as Density Functional Theory, Quantum Monte Carlo, Moller-Plesset Perturbation Theory among others. The computational complexity of the methods varies by a polynomial
order for a fixed number of electrons in the chemical system with DFT being amongst the fastest having a cubic computational complexity. With an increasing number of the electrons in the atomic structure, the computational complexity becomes in the worst-case
exponential, making it computationally demanding for investigating chemical systems with heavy elements or chemical systems with a large number of electrons. The ability to improve the computational complexity of these algorithms can significantly speed up
the discovery of new materials or new drugs.</p>

      <p>Recently, deep neural networks have been used as functional approximators of the solution of the Schrodinger Equation. Two different neural architectures, PauliNet [1] and FermiNet [2], can be used for approximating the
wave functions ansatz. Combining them with variational quantum Monte Carlo approximation of the energy function, yields a simulation technique which allows for training such a deep network without the requirement of labelled training data. Recently, [3] improved
performance of FermiNet by simplifying the architecture of the neural net and provided a comparison with PauliNet. The goal of this project is to experiment with different neural architectures approximating the ansatz and approximations of the energy functions via different simulation techniques and compare them with DFT solutions.</p>

      <p>[1] Hermann,
J., Schätzle, Z. &amp; Noé, F. Deep-neural-network solution of the electronic Schrödinger equation. Nat. Chem. 12, 891–897
(2020). <a href="https://doi.org/10.1038/s41557-020-0544-y">https://doi.org/10.1038/s41557-020-0544-y</a></p>

      <p>[2] David
Pfau, James S. Spencer, Alexander G. D. G. Matthews, and W. M. C. Foulkes, Ab inition solution of the many-electron Schrodinger equation with deep neural networks, Phys. Rev. Research 2, <a href="https://arxiv.org/abs/1909.02487">https://arxiv.org/abs/1909.02487</a></p>

      <p>[3] James
S. Spencer et all., Better, faster Fermionic Neural Networks, <a href="https://arxiv.org/abs/2011.07125">https://arxiv.org/abs/2011.07125</a></p>

    </div>
  </div>

</div>


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
    <script src="/bootstrap-3.1.1-dist/js/bootstrap.min.js"></script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-50547851-1', 'ox.ac.uk');
      ga('send', 'pageview');

    </script>
    </body>
</html>
